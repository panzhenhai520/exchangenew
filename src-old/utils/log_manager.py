#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ—¥å¿—ç®¡ç†å·¥å…·
æä¾›æ—¥å¿—æ¸…ç†ã€ç»Ÿè®¡ã€è½®è½¬ç­‰åŠŸèƒ½
"""

import os
import glob
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional

class LogManager:
    """æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = log_dir
        self.logger = logging.getLogger(__name__)
    
    def get_log_files(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ—¥å¿—æ–‡ä»¶ä¿¡æ¯"""
        if not os.path.exists(self.log_dir):
            return []
        
        # è·å–æ‰€æœ‰.logæ–‡ä»¶
        pattern = os.path.join(self.log_dir, "*.log*")
        log_files = glob.glob(pattern)
        file_list = []
        
        for log_file in sorted(log_files):
            try:
                file_stat = os.stat(log_file)
                filename = os.path.basename(log_file)
                
                file_info = {
                    'name': filename,
                    'size': self._format_file_size(file_stat.st_size),
                    'size_bytes': file_stat.st_size,
                    'modified_time': datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                    'is_current': filename == 'app.log'
                }
                file_list.append(file_info)
                
            except Exception as e:
                self.logger.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {log_file}, é”™è¯¯: {e}")
        
        return file_list
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"
    
    def get_log_stats(self) -> Dict:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        log_files = self.get_log_files()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_size_bytes = sum(f['size_bytes'] for f in log_files)
        current_log_size = 0
        archived_count = 0
        
        # æŸ¥æ‰¾å½“å‰æ—¥å¿—æ–‡ä»¶å¤§å°
        for file_info in log_files:
            if file_info['is_current']:
                current_log_size = file_info['size_bytes']
        
        # æŸ¥æ‰¾å½’æ¡£æ–‡ä»¶æ•°é‡
        archive_dir = os.path.join(os.path.dirname(self.log_dir), 'archive')
        if os.path.exists(archive_dir):
            archived_count = len([f for f in os.listdir(archive_dir) if f.endswith('.log')])
        
        stats = {
            "current_log_size": self._format_file_size(current_log_size),
            "total_logs_count": len(log_files),
            "total_size": self._format_file_size(total_size_bytes),
            "archived_count": archived_count,
            "total_size_mb": round(total_size_bytes / (1024 * 1024), 2)
        }
        
        return stats
    
    def clean_old_logs(self, days: int = 30) -> int:
        """æ¸…ç†æŒ‡å®šå¤©æ•°ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶"""
        if days <= 0:
            raise ValueError("å¤©æ•°å¿…é¡»å¤§äº0")
        
        cutoff_date = datetime.now() - timedelta(days=days)
        log_files = self.get_log_files()
        cleaned_count = 0
        
        for file_info in log_files:
            filename = file_info['name']
            # è·³è¿‡å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶
            if file_info['is_current']:
                continue
                
            try:
                log_file_path = os.path.join(self.log_dir, filename)
                file_stat = os.stat(log_file_path)
                modified_time = datetime.fromtimestamp(file_stat.st_mtime)
                
                if modified_time < cutoff_date:
                    os.remove(log_file_path)
                    cleaned_count += 1
                    self.logger.info(f"å·²åˆ é™¤æ—§æ—¥å¿—æ–‡ä»¶: {filename}")
                    
            except Exception as e:
                self.logger.error(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
        
        return cleaned_count
    
    def clean_large_logs(self, max_size_mb: int = 50) -> int:
        """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤§å°çš„æ—¥å¿—æ–‡ä»¶"""
        if max_size_mb <= 0:
            raise ValueError("æ–‡ä»¶å¤§å°é™åˆ¶å¿…é¡»å¤§äº0")
        
        log_files = self.get_log_files()
        cleaned_count = 0
        max_size_bytes = max_size_mb * 1024 * 1024
        
        for file_info in log_files:
            filename = file_info['name']
            # è·³è¿‡å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶
            if file_info['is_current']:
                continue
                
            try:
                log_file_path = os.path.join(self.log_dir, filename)
                file_stat = os.stat(log_file_path)
                
                if file_stat.st_size > max_size_bytes:
                    os.remove(log_file_path)
                    cleaned_count += 1
                    size_mb = file_stat.st_size / (1024 * 1024)
                    self.logger.info(f"å·²åˆ é™¤å¤§æ—¥å¿—æ–‡ä»¶: {filename} ({size_mb:.2f}MB)")
                    
            except Exception as e:
                self.logger.error(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
        
        return cleaned_count
    
    def compress_old_logs(self, days: int = 7) -> int:
        """å‹ç¼©æŒ‡å®šå¤©æ•°ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶"""
        try:
            import gzip
            import shutil
        except ImportError:
            self.logger.error("å‹ç¼©åŠŸèƒ½éœ€è¦gzipæ¨¡å—")
            return 0
        
        if days <= 0:
            raise ValueError("å¤©æ•°å¿…é¡»å¤§äº0")
        
        cutoff_date = datetime.now() - timedelta(days=days)
        log_files = self.get_log_files()
        compressed_count = 0
        
        for file_info in log_files:
            filename = file_info['name']
            # è·³è¿‡å·²ç»å‹ç¼©çš„æ–‡ä»¶
            if filename.endswith('.gz'):
                continue
                
            # è·³è¿‡å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶
            if file_info['is_current']:
                continue
                
            try:
                log_file_path = os.path.join(self.log_dir, filename)
                file_stat = os.stat(log_file_path)
                modified_time = datetime.fromtimestamp(file_stat.st_mtime)
                
                if modified_time < cutoff_date:
                    # å‹ç¼©æ–‡ä»¶
                    compressed_file_path = log_file_path + '.gz'
                    with open(log_file_path, 'rb') as f_in:
                        with gzip.open(compressed_file_path, 'wb') as f_out:
                            shutil.copyfileobj(f_in, f_out)
                    
                    # åˆ é™¤åŸæ–‡ä»¶
                    os.remove(log_file_path)
                    compressed_count += 1
                    self.logger.info(f"å·²å‹ç¼©æ—¥å¿—æ–‡ä»¶: {filename} -> {filename}.gz")
                    
            except Exception as e:
                self.logger.error(f"å‹ç¼©æ—¥å¿—æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
        
        return compressed_count
    
    def archive_logs(self, archive_dir: str = "archive") -> int:
        """å½’æ¡£æ—§æ—¥å¿—æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•"""
        if not os.path.exists(archive_dir):
            os.makedirs(archive_dir)
        
        log_files = self.get_log_files()
        archived_count = 0
        
        # åªå½’æ¡£éå½“å‰æ—¥å¿—æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯app.log.1, app.log.2ç­‰ï¼‰
        for file_info in log_files:
            filename = file_info['name']
            
            # è·³è¿‡å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶
            if file_info['is_current']:
                continue
                
            try:
                log_file_path = os.path.join(self.log_dir, filename)
                archive_path = os.path.join(archive_dir, filename)
                
                # å¦‚æœå½’æ¡£æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
                if os.path.exists(archive_path):
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    name, ext = os.path.splitext(filename)
                    archive_path = os.path.join(archive_dir, f"{name}_{timestamp}{ext}")
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°å½’æ¡£ç›®å½•
                os.rename(log_file_path, archive_path)
                archived_count += 1
                self.logger.info(f"å·²å½’æ¡£æ—¥å¿—æ–‡ä»¶: {filename} -> {os.path.basename(archive_path)}")
                
            except Exception as e:
                self.logger.error(f"å½’æ¡£æ—¥å¿—æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
        
        return archived_count
    
    def get_log_content(self, filename: str, max_lines: int = 1000) -> str:
        """è·å–æ—¥å¿—æ–‡ä»¶å†…å®¹"""
        log_file_path = os.path.join(self.log_dir, filename)
        
        if not os.path.exists(log_file_path):
            raise FileNotFoundError(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        try:
            with open(log_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # é™åˆ¶è¿”å›çš„è¡Œæ•°ä»¥é¿å…å†…å­˜é—®é¢˜
                if len(lines) > max_lines:
                    lines = lines[-max_lines:]
                return ''.join(lines)
        except Exception as e:
            self.logger.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {log_file_path}, é”™è¯¯: {e}")
            raise
    
    def delete_log_file(self, filename: str) -> bool:
        """åˆ é™¤æŒ‡å®šçš„æ—¥å¿—æ–‡ä»¶"""
        log_file_path = os.path.join(self.log_dir, filename)
        
        # ä¸å…è®¸åˆ é™¤å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶
        if filename == "app.log":
            raise ValueError("ä¸èƒ½åˆ é™¤å½“å‰æ´»åŠ¨çš„æ—¥å¿—æ–‡ä»¶")
        
        if not os.path.exists(log_file_path):
            raise FileNotFoundError(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        try:
            os.remove(log_file_path)
            self.logger.info(f"å·²åˆ é™¤æ—¥å¿—æ–‡ä»¶: {log_file_path}")
            return True
        except Exception as e:
            self.logger.error(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {log_file_path}, é”™è¯¯: {e}")
            raise
    
    def print_stats(self):
        """æ‰“å°æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_log_stats()
        
        print(f"\nğŸ“Š æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")
        print(f"   æ—¥å¿—ç›®å½•: {os.path.abspath(self.log_dir)}")
        
        if stats['files']:
            print(f"\nğŸ“ æ–‡ä»¶è¯¦æƒ…:")
            for file_info in stats['files']:
                print(f"   {file_info['name']:<20} {file_info['size_mb']:>8.2f}MB  {file_info['modified']}  ({file_info['age_days']}å¤©å‰)")
        
        print()


def main():
    """å‘½ä»¤è¡Œå·¥å…·ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ExchangeOKæ—¥å¿—ç®¡ç†å·¥å…·")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºæ—¥å¿—ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--clean-old", type=int, metavar="DAYS", help="æ¸…ç†Nå¤©å‰çš„æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--clean-large", type=int, metavar="MB", help="æ¸…ç†è¶…è¿‡N MBçš„æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--compress", type=int, metavar="DAYS", help="å‹ç¼©Nå¤©å‰çš„æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--archive", action="store_true", help="å½’æ¡£æ—§æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--log-dir", default="logs", help="æ—¥å¿—ç›®å½•è·¯å¾„")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ—¥å¿—ç®¡ç†å™¨
    log_manager = LogManager(args.log_dir)
    
    if args.stats:
        log_manager.print_stats()
    
    if args.clean_old:
        count = log_manager.clean_old_logs(args.clean_old)
        print(f"[OK] å·²æ¸…ç† {count} ä¸ªæ—§æ—¥å¿—æ–‡ä»¶")
    
    if args.clean_large:
        count = log_manager.clean_large_logs(args.clean_large)
        print(f"[OK] å·²æ¸…ç† {count} ä¸ªå¤§æ—¥å¿—æ–‡ä»¶")
    
    if args.compress:
        count = log_manager.compress_old_logs(args.compress)
        print(f"[OK] å·²å‹ç¼© {count} ä¸ªæ—¥å¿—æ–‡ä»¶")
    
    if args.archive:
        count = log_manager.archive_logs()
        print(f"[OK] å·²å½’æ¡£ {count} ä¸ªæ—¥å¿—æ–‡ä»¶")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ“ä½œï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not any([args.stats, args.clean_old, args.clean_large, args.compress, args.archive]):
        parser.print_help()


if __name__ == "__main__":
    main() 